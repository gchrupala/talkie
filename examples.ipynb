{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting activations\n",
    "\n",
    "\n",
    "Download and unzip directory with model data from: https://drive.google.com/open?id=14jWnakZn5JvtJpqalBJIkmwCPbbHd4gn\n",
    "This model has been trained on [The Places Audio Caption Corpus] (https://groups.csail.mit.edu/sls/downloads/placesaudio/index.cgi).\n",
    "\n",
    "\n",
    "We will extract activations from two example audio files included in the repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vg.activations\n",
    "modelpath = \"models/places-stack-s2-t.-s2i2-s2t.-t2s.-t2i.--f/model.12.pkl\"\n",
    "paths = [\"data/example_audio/667626_18933d713e_0.wav\", \"data/example_audio/3637013_c675de7705_0.wav\"]\n",
    "data = vg.activations.from_audio(modelpath, paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a list of numpy arrays, one array per audio file. \n",
    "The arrays are shaped as (TIMESTEP, LAYER, FEATURE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(131, 4, 1024)\n",
      "(215, 4, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data[0].shape)\n",
    "print(data[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forced alignment\n",
    "\n",
    "You will need to install the [Gentle toolkit](https://github.com/lowerquality/gentle) and the associated Python library gentle.\n",
    "\n",
    "Let's align an audio file with the transcript of the speech. The output will be a Python dictionary with the alignment information. The phonetic notation uses the Arpabet system, with some added suffixes. For example the second phoneme of the word *girl* is noted as `er_I`, indicating the phoneme written as /ɝ/ or\n",
    "/ɹ/ in IPA. The suffix `_I` indicates that this phoneme occurs inside a word (as opposed to beginning or end).\n",
    "\n",
    "See https://raw.githubusercontent.com/gchrupala/encoding-of-phonology/master/src/phonemes.txt for a mapping between Arpabet and IPA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transcript': 'A girl is stretched out in shallow water.',\n",
       " 'words': [{'alignedWord': 'a',\n",
       "   'case': 'success',\n",
       "   'end': 0.39,\n",
       "   'endOffset': 1,\n",
       "   'phones': [{'duration': 0.07, 'phone': 'ah_S'}],\n",
       "   'start': 0.32,\n",
       "   'startOffset': 0,\n",
       "   'word': 'A'},\n",
       "  {'alignedWord': 'girl',\n",
       "   'case': 'success',\n",
       "   'end': 0.66,\n",
       "   'endOffset': 6,\n",
       "   'phones': [{'duration': 0.1, 'phone': 'g_B'},\n",
       "    {'duration': 0.1, 'phone': 'er_I'},\n",
       "    {'duration': 0.07, 'phone': 'l_E'}],\n",
       "   'start': 0.39,\n",
       "   'startOffset': 2,\n",
       "   'word': 'girl'},\n",
       "  {'alignedWord': 'is',\n",
       "   'case': 'success',\n",
       "   'end': 0.78,\n",
       "   'endOffset': 9,\n",
       "   'phones': [{'duration': 0.06, 'phone': 'ih_B'},\n",
       "    {'duration': 0.06, 'phone': 'z_E'}],\n",
       "   'start': 0.66,\n",
       "   'startOffset': 7,\n",
       "   'word': 'is'},\n",
       "  {'alignedWord': 'stretched',\n",
       "   'case': 'success',\n",
       "   'end': 1.2,\n",
       "   'endOffset': 19,\n",
       "   'phones': [{'duration': 0.03, 'phone': 's_B'},\n",
       "    {'duration': 0.08, 'phone': 't_I'},\n",
       "    {'duration': 0.05, 'phone': 'r_I'},\n",
       "    {'duration': 0.09, 'phone': 'eh_I'},\n",
       "    {'duration': 0.09, 'phone': 'ch_I'},\n",
       "    {'duration': 0.08, 'phone': 't_E'}],\n",
       "   'start': 0.78,\n",
       "   'startOffset': 10,\n",
       "   'word': 'stretched'},\n",
       "  {'alignedWord': 'out',\n",
       "   'case': 'success',\n",
       "   'end': 1.48,\n",
       "   'endOffset': 23,\n",
       "   'phones': [{'duration': 0.19, 'phone': 'aw_B'},\n",
       "    {'duration': 0.09, 'phone': 't_E'}],\n",
       "   'start': 1.2,\n",
       "   'startOffset': 20,\n",
       "   'word': 'out'},\n",
       "  {'alignedWord': 'in',\n",
       "   'case': 'success',\n",
       "   'end': 1.72,\n",
       "   'endOffset': 26,\n",
       "   'phones': [{'duration': 0.1, 'phone': 'ih_B'},\n",
       "    {'duration': 0.1, 'phone': 'n_E'}],\n",
       "   'start': 1.52,\n",
       "   'startOffset': 24,\n",
       "   'word': 'in'},\n",
       "  {'alignedWord': 'shallow',\n",
       "   'case': 'success',\n",
       "   'end': 2.14,\n",
       "   'endOffset': 34,\n",
       "   'phones': [{'duration': 0.14, 'phone': 'sh_B'},\n",
       "    {'duration': 0.09, 'phone': 'ae_I'},\n",
       "    {'duration': 0.1, 'phone': 'l_I'},\n",
       "    {'duration': 0.09, 'phone': 'ow_E'}],\n",
       "   'start': 1.72,\n",
       "   'startOffset': 27,\n",
       "   'word': 'shallow'},\n",
       "  {'alignedWord': 'water',\n",
       "   'case': 'success',\n",
       "   'end': 2.4000000000000004,\n",
       "   'endOffset': 40,\n",
       "   'phones': [{'duration': 0.06, 'phone': 'w_B'},\n",
       "    {'duration': 0.11, 'phone': 'ao_I'},\n",
       "    {'duration': 0.07, 'phone': 't_I'},\n",
       "    {'duration': 0.02, 'phone': 'er_E'}],\n",
       "   'start': 2.14,\n",
       "   'startOffset': 35,\n",
       "   'word': 'water'}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vg.align\n",
    "path = \"data/example_audio/667626_18933d713e_0.wav\"\n",
    "text = \"A girl is stretched out in shallow water.\"\n",
    "alignment = vg.align.align(path, text)\n",
    "alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phoneme activations\n",
    "\n",
    "Given neural activations for an utterance and an alignment, we can extract the phoneme labels with their corresponding mean-pooled features using the function `vg.align.phoneme_activations`.\n",
    "The output will be two numpy arrays:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24,)\n",
      "(24, 4, 1024)\n"
     ]
    }
   ],
   "source": [
    "labels, features = vg.align.phoneme_activations(data[0], alignment)\n",
    "print(labels.shape)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `vg.align.from_audio` will extract the same information directly from audio with the associated transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51,)\n",
      "(51, 4, 1024)\n"
     ]
    }
   ],
   "source": [
    "modelpath = \"models/places-stack-s2-t.-s2i2-s2t.-t2s.-t2i.--f/model.12.pkl\"\n",
    "paths = [\"data/example_audio/667626_18933d713e_0.wav\", \"data/example_audio/3637013_c675de7705_0.wav\"]\n",
    "texts = [\"A girl is stretched out in shallow water.\", \"A couple stands close at the water's edge.\"]\n",
    "labels, features = vg.align.from_audio(modelpath, paths, texts)\n",
    "print(labels.shape)\n",
    "print(features.shape)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
